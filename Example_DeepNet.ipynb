{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Example_DeepNet.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AE1RGXgHjU6"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pdh21/OCF_PVmapper/blob/main/Example_DeepNet.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "![](https://avatars.githubusercontent.com/u/48357542?s=200&v=4)\n",
        "\n",
        "## PV mapping Example:\n",
        "[Peter Hurley](http://pdh21.github.io/) \n",
        "\n",
        "In this notebook, we will give a simple example of training a deep net to detect solar panels from remote sensing data. \n",
        "\n",
        "As with most neural net projects, we need to:\n",
        "1. Define training data: input tensors and target tensors.\n",
        "2. Define a network of layers (or model ) that maps inputs to targets.\n",
        "3. Configure the learning process by choosing a loss function, an optimizer\n",
        "some metrics to monitor.\n",
        "4. Iterate on training data by calling the fit() method of your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkUTlJf9HjVR",
        "outputId": "c67a1232-32b2-4b49-ef48-ac0acdfe8e4a"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2y4i5EL4XAU",
        "outputId": "2a2bf3c4-6715-44ac-8df9-12c678b94db1"
      },
      "source": [
        "cd gdrive/MyDrive/PVmapping/cutouts"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/PVmapping/cutouts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXJC1747bOJZ",
        "outputId": "ae3eddea-c340-494c-cc99-bdcb6fce28f6"
      },
      "source": [
        "pip install tensorflow-io"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-io in /usr/local/lib/python3.6/dist-packages (0.17.0)\n",
            "Requirement already satisfied: tensorflow<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-io) (2.4.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (0.2.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (2.10.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (3.12.4)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (0.10.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.19.5)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (2.4.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.32.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (2.4.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (3.7.4.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (0.36.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.12.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (0.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (53.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.24.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (4.7)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (4.2.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (3.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxnihacZY15i",
        "outputId": "95b3f2c6-ec51-4353-be28-5634d97ca952"
      },
      "source": [
        "import os, sys, math\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "AUTO = tf.data.experimental.AUTOTUNE # used in tf.data.Dataset API"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryl2ndzJX6J0"
      },
      "source": [
        "FILE_PATTERN='./*aerial*.tif'\n",
        "OUTPUT = '../cutouts_tfrecords/'  # prefix for output file names\n",
        "TARGET_SIZE = [81,81]\n",
        "\n",
        "\n",
        "filenames_dataset = tf.data.Dataset.list_files('./*aerial*.tif')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTH0t7n2C74q"
      },
      "source": [
        "SHARDS = 16\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAsBSJvcYlrX",
        "outputId": "a7ad9993-cd3f-4997-9439-62a7a0ceafbb"
      },
      "source": [
        "nb_images = len(tf.io.gfile.glob(FILE_PATTERN))\n",
        "shard_size = math.ceil(1.0 * nb_images / SHARDS)\n",
        "print(\"Pattern matches {} images which will be rewritten as {} .tfrec files containing {} images each.\".format(nb_images, SHARDS, shard_size))\n",
        "\n",
        "def decode_tif_and_label(filename):\n",
        "  bits_aerial = tf.io.read_file(filename)\n",
        "  bits_binary = tf.io.read_file(tf.strings.regex_replace(filename, \"aerial\", \"binary\"))\n",
        "  image_aerial = tfio.experimental.image.decode_tiff(bits_aerial)[:,:,0:3]\n",
        "  image_binary = tfio.experimental.image.decode_tiff(bits_binary)[:,:,0:1]\n",
        "\n",
        "\n",
        "  label = tf.strings.split(tf.expand_dims(filename, axis=-1), sep='_')\n",
        "  #num = label.values[-2]\n",
        "  pos_neg=  label.values[0]\n",
        "  #im_type=label_3.values[1]\n",
        "  return image_aerial,image_binary,pos_neg"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pattern matches 3999 images which will be rewritten as 16 .tfrec files containing 250 images each.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3NqjxxFZ4QH"
      },
      "source": [
        "image_dataset = filenames_dataset.map(decode_tif_and_label)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lADmwBVQblHE"
      },
      "source": [
        "def recompress_image(image_aerial,image_binary,label):\n",
        "  height = tf.shape(image_aerial)[0]\n",
        "  width = tf.shape(image_aerial)[1]\n",
        "  image_aerial = tf.cast(image_aerial, tf.uint8)\n",
        "  image_binary = tf.cast(image_binary, tf.uint8)\n",
        "\n",
        "  image_aerial = tf.image.encode_jpeg(image_aerial, optimize_size=True, chroma_downsampling=False)\n",
        "  image_binary = tf.image.encode_jpeg(image_binary, optimize_size=True, chroma_downsampling=False)\n",
        "\n",
        "\n",
        "  return image_aerial,image_binary,label,width,height\n",
        "\n",
        "dataset3 = image_dataset.map(recompress_image, num_parallel_calls=AUTO)\n",
        "dataset3 = dataset3.batch(shard_size) # sharding: there will be one \"batch\" of images per file "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-l8PWSq_k25"
      },
      "source": [
        "## Write dataset to TFRecord *files*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECiFAAisAr4b",
        "outputId": "e0147f0d-a395-4849-84e4-70c4cb185973"
      },
      "source": [
        "# Three types of data can be stored in TFRecords: bytestrings, integers and floats\n",
        "# They are always stored as lists, a single data element will be a list of size 1\n",
        "\n",
        "def _bytestring_feature(list_of_bytestrings):\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=list_of_bytestrings))\n",
        "\n",
        "def _int_feature(list_of_ints): # int64\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))\n",
        "\n",
        "def _float_feature(list_of_floats): # float32\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))\n",
        "  \n",
        "\n",
        "def to_tfrecord(tfrec_filewriter, img_aerial_bytes, image_binary_bytes, label,height,width):  \n",
        "\n",
        "  feature = {\n",
        "      \"image_aerial\": _bytestring_feature([img_aerial_bytes]), # one image in the list\n",
        "      \"image_binary\": _bytestring_feature([image_binary_bytes]),       \n",
        "      \n",
        "      # additional (not very useful) fields to demonstrate TFRecord writing/reading of different types of data\n",
        "      \"label\":         _bytestring_feature([label]),          # fixed length (1) list of strings, the text label\n",
        "      \"size\":          _int_feature([height, width]),         # fixed length (2) list of ints\n",
        "\n",
        "  }\n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "  \n",
        "print(\"Writing TFRecords\")\n",
        "for shard, (image_aerial, image_binary, label, height, width) in enumerate(dataset3):\n",
        "  # batch size used as shard size here\n",
        "  shard_size = image_aerial.numpy().shape[0]\n",
        "  # good practice to have the number of records in the filename\n",
        "  filename = OUTPUT + \"{:02d}-{}.tfrec\".format(shard, shard_size)\n",
        "  \n",
        "  with tf.io.TFRecordWriter(filename) as out_file:\n",
        "    for i in range(shard_size):\n",
        "      example = to_tfrecord(out_file,\n",
        "                            image_aerial.numpy()[i], # re-compressed image: already a byte string\n",
        "                            image_binary.numpy()[i], # re-compressed image: already a byte string\n",
        "                            label.numpy()[i],\n",
        "                            height.numpy()[i],\n",
        "                            width.numpy()[i])\n",
        "\n",
        "      out_file.write(example.SerializeToString())\n",
        "    print(\"Wrote file {} containing {} records\".format(filename, shard_size))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing TFRecords\n",
            "Wrote file ../cutouts_tfrecords/00-250.tfrec containing 250 records\n",
            "Wrote file ../cutouts_tfrecords/01-250.tfrec containing 250 records\n",
            "Wrote file ../cutouts_tfrecords/02-250.tfrec containing 250 records\n",
            "Wrote file ../cutouts_tfrecords/03-250.tfrec containing 250 records\n",
            "Wrote file ../cutouts_tfrecords/04-250.tfrec containing 250 records\n",
            "Wrote file ../cutouts_tfrecords/05-250.tfrec containing 250 records\n",
            "Wrote file ../cutouts_tfrecords/06-250.tfrec containing 250 records\n",
            "Wrote file ../cutouts_tfrecords/07-250.tfrec containing 250 records\n",
            "Wrote file ../cutouts_tfrecords/08-250.tfrec containing 250 records\n",
            "Wrote file ../cutouts_tfrecords/09-250.tfrec containing 250 records\n",
            "Wrote file ../cutouts_tfrecords/10-250.tfrec containing 250 records\n",
            "Wrote file ../cutouts_tfrecords/11-250.tfrec containing 250 records\n",
            "Wrote file ../cutouts_tfrecords/12-250.tfrec containing 250 records\n",
            "Wrote file ../cutouts_tfrecords/13-250.tfrec containing 250 records\n",
            "Wrote file ../cutouts_tfrecords/14-250.tfrec containing 250 records\n",
            "Wrote file ../cutouts_tfrecords/15-249.tfrec containing 249 records\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLyvcF3Ppzus"
      },
      "source": [
        "## Read  from TFRecord Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQlagrwLp2_G"
      },
      "source": [
        "def read_tfrecord(example):\n",
        "    features = {\n",
        "        \"image_aerial\": tf.io.FixedLenFeature([], tf.string),  # tf.string = bytestring (not text string)\n",
        "        \"image_binary\": tf.io.FixedLenFeature([], tf.string),   # shape [] means scalar\n",
        "        \n",
        "        # additional (not very useful) fields to demonstrate TFRecord writing/reading of different types of data\n",
        "        \"label\":         tf.io.FixedLenFeature([], tf.string),  # one bytestring\n",
        "        \"size\":          tf.io.FixedLenFeature([2], tf.int64),  # two integers\n",
        "\n",
        "    }\n",
        "    # decode the TFRecord\n",
        "    example = tf.io.parse_single_example(example, features)\n",
        "    \n",
        "    # FixedLenFeature fields are now ready to use: exmple['size']\n",
        "    # VarLenFeature fields require additional sparse_to_dense decoding\n",
        "    \n",
        "    image_aerial = tf.image.decode_jpeg(example['image_aerial'], channels=3)\n",
        "    image_aerial = tf.reshape(image_aerial, [*TARGET_SIZE, 3])\n",
        "\n",
        "    image_binary = tf.image.decode_jpeg(example['image_binary'], channels=3)\n",
        "    image_binary = tf.reshape(image_binary, [*TARGET_SIZE, 3])\n",
        "    \n",
        "    \n",
        "    label  = example['label']\n",
        "    height = example['size'][0]\n",
        "    width  = example['size'][1]\n",
        "    return image_aerial,image_binary, label, height, width\n",
        "    \n",
        "# read from TFRecords. For optimal performance, read from multiple\n",
        "# TFRecord files at once and set the option experimental_deterministic = False\n",
        "# to allow order-altering optimizations.\n",
        "\n",
        "option_no_order = tf.data.Options()\n",
        "option_no_order.experimental_deterministic = False\n",
        "\n",
        "filenames = tf.io.gfile.glob(OUTPUT + \"*.tfrec\")\n",
        "dataset4 = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "dataset4 = dataset4.with_options(option_no_order)\n",
        "dataset4 = dataset4.map(read_tfrecord, num_parallel_calls=AUTO)\n",
        "dataset4 = dataset4.shuffle(300)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRAYErrep0rp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}