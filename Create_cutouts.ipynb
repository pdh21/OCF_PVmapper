{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having created the updated, more accurate solar raster files, I need to create cutouts for the deepnet.\n",
    "\n",
    "I will create one massive polygon from all the tiles and another with all the panels. I will then randomly sample points within the polygons, and create square cutouts centered at those points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make polygon of all Exeter tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import PIL\n",
    "import glob\n",
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "import geopandas as gpd\n",
    "from fiona.crs import from_epsg\n",
    "from shapely.geometry import box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path='/Volumes/pdh_storage_2/OCF/PV_Mapping/data/raw/Exeter/'\n",
    "aerial_files=glob.glob(training_path+'GeoTiff_*/*.tif')\n",
    "solar_files=glob.glob(training_path+'solar-rasters_v2/*.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundingBox(left=266000.0, bottom=105000.0, right=267000.0, top=106000.0)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = rasterio.open(solar_files[0])\n",
    "dataset.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo=[]\n",
    "for i,d in enumerate(solar_files):\n",
    "    dataset = rasterio.open(d)\n",
    "    geo.append(gpd.GeoDataFrame({\"id\":1,\"geometry\":[box(*dataset.bounds)],'tile':d.split('/')[-1].split('.tif')[0]}))\n",
    "polygons_all=pd.concat(geo)\n",
    "polygons_all.reset_index(inplace=True)\n",
    "polygons_all=polygons_all.set_crs(epsg=27700)\n",
    "#save as geojson\n",
    "polygons_all.to_file(filename='Exeter_tiles_orig.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process for making cutouts\n",
    "1. Use the geopandas dissolve (as documented [here](https://stackoverflow.com/questions/34325030/merging-two-geojson-polygons-in-python)) to create union of tiles\n",
    "2. Use pointpats to create random points within polygon\n",
    "Use GeoSeries.buffer to create buffer around panels polygon\n",
    "3. make cutouts around those points, checking that there are no solar panels in the negative images and that the box isnt hitting tile boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the polygons for all the tiles to get a mask from which to generate random points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons_all['new_column'] = 0\n",
    "polygons_new = polygons_all.dissolve(by='new_column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons_new.to_file(filename='Exeter_tiles_union.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [`pointpats`](https://github.com/pysal/pointpats/blob/master/notebooks/process.ipynb) to generate random points within the maskpolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointpats import PoissonPointProcess, PoissonClusterPointProcess, Window, poly_from_bbox, PointPattern\n",
    "import libpysal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "window=Window(libpysal.cg.asShape(polygons_new.geometry[0]).parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "#note as conditioning=False and asPP=False makes this a simulate a N-conditioned CSR and point series respectively\n",
    "samples = PoissonPointProcess(window, 200, 1, conditioning=False, asPP=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating samples works, now I need to create mask around the panels, including a buffer and combine so that I have the following masks from which to generate samples:\n",
    "1. A non-panel mask = aerial tiles union - buffer panel mask (- aerial tiles buffer)\n",
    "2. A panel mask = panel mask union (- aerial tiles buffer)\n",
    "\n",
    "To make it simpler when making cutouts, I will be subtracting the aerial tiles buffer. This a buffer around the edge of the tiles so that I can generate square cutouts without having to worry about going over numerous tif files. I could make the cutouts such that if one did cross a tiff boundary it could deal with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "geopolygons=glob.glob(training_path+'/polygons/*.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_gpd=[]\n",
    "for i,p in enumerate(geopolygons):\n",
    "    panel_gpd.append(gpd.read_file(p).set_crs(epsg=27700,allow_override=True))\n",
    "all_panels_gpd=pd.concat(panel_gpd)\n",
    "#reindex the dataframe\n",
    "all_panels_gpd.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set buffer size\n",
    "buffer_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_panels_gpd_buffer=all_panels_gpd.buffer(buffer_size)\n",
    "all_panels_gpd_buffer.to_file(filename='all_panels_buffer.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_panels_gpd.to_file(filename='all_panels.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create aerial tile buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "aerial_tile_buffer=polygons_all.buffer(buffer_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "aerial_tile_buffer.to_file(filename='buffered_tiles.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "aerial_tile_buffer_df=gpd.GeoDataFrame(geometry=aerial_tile_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffered_tiles=[]\n",
    "for i in range(0,len(aerial_tile_buffer_df)):\n",
    "    buffered_tiles.append(gpd.overlay(aerial_tile_buffer_df.iloc[[i]],aerial_tile_buffer_df.drop(i), how='difference'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffered_tiles=pd.concat(buffered_tiles)\n",
    "buffered_tiles.to_file(filename='buffered_tiles_intersect.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make final masks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neen to create a small buffer for intersction to work (as described here https://www.programmersought.com/article/69515213493/)\n",
    "all_panels_gpd_buffer_small=all_panels_gpd.buffer(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the first overlay subtracts the buffered panels, the outer overlay deals with the outer buffered tiles that extend beyond original tile\n",
    "negative_mask=gpd.overlay(gpd.overlay(buffered_tiles,gpd.GeoDataFrame(geometry=all_panels_gpd_buffer),how='difference'),polygons_new,how='intersection')\n",
    "\n",
    "positive_mask=gpd.overlay(buffered_tiles,gpd.GeoDataFrame(geometry=all_panels_gpd_buffer_small),how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_mask.to_file(filename='negative_mask.geojson', driver='GeoJSON')\n",
    "positive_mask.to_file(filename='positive_mask.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate positions of cutouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_mask['new_column'] = 0\n",
    "negative_mask = negative_mask.dissolve(by='new_column')\n",
    "#positive_mask['new_column'] = 0\n",
    "#positive_mask = positive_mask.dissolve(by='new_column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "window=Window(libpysal.cg.asShape(negative_mask.geometry[0]).parts)\n",
    "np.random.seed(5)\n",
    "#note as conditioning=False and asPP=False makes this a simulate a N-conditioned CSR and point series respectively\n",
    "negative_samples = PoissonPointProcess(window, 2000, 1, conditioning=False, asPP=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_geo=gpd.GeoDataFrame(geometry=gpd.points_from_xy(negative_samples.realizations[0][:,0],negative_samples.realizations[0][:,1]))\n",
    "neg_geo=neg_geo.set_crs(epsg=27700)\n",
    "neg_geo.to_file(filename='neg_samples.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The positive point process takes too long because it is not optimized to deal with multipolygons. One way to do this would be to sample from discrete distribution, weighted by fractional area of each polygon\n",
    "\n",
    "NOTE: At the moment, the solar farms are going to be picked more, I may want to do something to lessen the weight on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_mask['weight']=positive_mask.area/positive_mask.area.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "npos=2000\n",
    "positive_samples=[]\n",
    "pos_polygon=np.random.choice(positive_mask.index,npos, p=positive_mask['weight'])\n",
    "for i in range(0,npos):\n",
    "    window=Window(libpysal.cg.asShape(positive_mask.geometry[pos_polygon[i]]).parts)\n",
    "    positive_samples.append(PoissonPointProcess(window, 1, 1, conditioning=False, asPP=False).realizations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_samples=np.asarray(positive_samples).reshape(npos,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_geo=gpd.GeoDataFrame(geometry=gpd.points_from_xy(positive_samples[:,0],positive_samples[:,1]))\n",
    "pos_geo=pos_geo.set_crs(epsg=27700)\n",
    "pos_geo.to_file(filename='pos_samples.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make cutouts, I need to:\n",
    "    1. find what tile each of the points are in\n",
    "    2. make cutout, centered on that position for\n",
    "        1. Aerial image\n",
    "        2. binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the tile for each positive and negative sample\n",
    "pos_geo['tile']=''\n",
    "neg_geo['tile']=''\n",
    "for i in range(len(polygons_all)):\n",
    "    pos_geo.loc[pos_geo.within(polygons_all.loc[i, 'geometry']).values,'tile']=polygons_all.loc[i, 'tile']\n",
    "    neg_geo.loc[neg_geo.within(polygons_all.loc[i, 'geometry']).values,'tile']=polygons_all.loc[i, 'tile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box, mapping\n",
    "import fiona\n",
    "from rasterio import transform\n",
    "from fiona.crs import from_epsg\n",
    "import pycrs\n",
    "from rasterio.mask import mask\n",
    "\n",
    "def getFeatures(gdf):\n",
    "    \"\"\"Function to parse features from GeoDataFrame in such a manner that rasterio wants them\"\"\"\n",
    "    import json\n",
    "    return [json.loads(gdf.to_json())['features'][0]['geometry']]\n",
    "\n",
    "def make_aerial_cutout(tif_file,centre_point,width,out_tif):\n",
    "    dataset = rasterio.open(tif_file)\n",
    "    \n",
    "    bbox = box(centre_point.xy[0][0]-width,centre_point.xy[1][0]-width,centre_point.xy[0][0]+width,centre_point.xy[1][0]+width)\n",
    "    geo = gpd.GeoDataFrame({'geometry': bbox}, index=[0], crs=from_epsg(27700))\n",
    "    geo = geo.to_crs(crs=dataset.crs.data)\n",
    "    coords = getFeatures(geo)\n",
    "    out_img, out_transform = mask(dataset, shapes=coords, crop=True)\n",
    "    #crop solar raster file\n",
    "    #rast=np.empty_like(out_img[0,:,:]).astype(float)\n",
    "    #rast[:,:]=0.8\n",
    "    #rast[ymin_np:ymax_np,xmin_np:xmax_np]=1.2\n",
    "    #out_img=out_img*rast\n",
    "    # Copy the metadata\n",
    "    out_meta = dataset.meta.copy()\n",
    "\n",
    "    # Parse EPSG code\n",
    "    epsg_code = int(dataset.crs.data['init'][5:])\n",
    "\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "         \"height\": out_img.shape[1],\n",
    "         \"width\": out_img.shape[2],\n",
    "         \"transform\": out_transform})\n",
    "    with rasterio.open(out_tif, \"w\", **out_meta) as dest:\n",
    "        dest.write(out_img.astype(np.uint8))\n",
    "        \n",
    "def make_binary_cutout(tif_file,centre_point,width,out_tif):\n",
    "    dataset = rasterio.open(tif_file)\n",
    "    bbox = box(centre_point.xy[0][0]-width,centre_point.xy[1][0]-width,centre_point.xy[0][0]+width,centre_point.xy[1][0]+width)\n",
    "    geo = gpd.GeoDataFrame({'geometry': bbox}, index=[0], crs=from_epsg(27700))\n",
    "    geo = geo.to_crs(crs=dataset.crs.data)\n",
    "    coords = getFeatures(geo)\n",
    "    out_image, out_transform = mask(dataset, shapes=coords, crop=True)\n",
    "\n",
    "    out_meta = dataset.meta.copy()\n",
    "\n",
    "    # Parse EPSG code\n",
    "    epsg_code = int(dataset.crs.data['init'][5:])\n",
    "\n",
    "\n",
    "    \n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "     \"height\": out_image.shape[1],\n",
    "     \"width\": out_image.shape[2],\n",
    "     \"transform\": out_transform,\n",
    "     \"count\":1,\n",
    "     'nodata':0.0,\n",
    "     'compress':'lzw'})\n",
    "    with rasterio.open(out_tif, \"w\", **out_meta) as dest:\n",
    "        dest.write(out_image.astype(rasterio.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pdh21/anaconda3/envs/m5_forecasting/lib/python3.8/site-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    }
   ],
   "source": [
    "#loop over every sample and make both cutouts for both aerial and binary tif\n",
    "for i in range(0,len(pos_geo)):\n",
    "    out_path='/Volumes/pdh_storage_2/OCF/PV_Mapping/data/raw/Exeter/deepnet_cutouts/positive/'\n",
    "    aerial_file=list(filter(lambda x: pos_geo['tile'][i].split('_')[0] in x, aerial_files))[0]\n",
    "    solar_file=list(filter(lambda x: pos_geo['tile'][i] in x, solar_files))[0]\n",
    "    make_aerial_cutout(aerial_file,pos_geo['geometry'][i],10,out_path+'train_{}.tif'.format(i))\n",
    "    make_binary_cutout(solar_file,pos_geo['geometry'][i],10,out_path+'train_binary_{}.tif'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pdh21/anaconda3/envs/m5_forecasting/lib/python3.8/site-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    }
   ],
   "source": [
    "#loop over every sample and make both cutouts for both aerial and binary tif\n",
    "for i in range(0,len(neg_geo)):\n",
    "    out_path='/Volumes/pdh_storage_2/OCF/PV_Mapping/data/raw/Exeter/deepnet_cutouts/negative/'\n",
    "    aerial_file=list(filter(lambda x: neg_geo['tile'][i].split('_')[0] in x, aerial_files))[0]\n",
    "    solar_file=list(filter(lambda x: neg_geo['tile'][i] in x, solar_files))[0]\n",
    "    try:\n",
    "        make_aerial_cutout(aerial_file,neg_geo['geometry'][i],10,out_path+'train_{}.tif'.format(i))\n",
    "        make_binary_cutout(solar_file,neg_geo['geometry'][i],10,out_path+'train_binary_{}.tif'.format(i))\n",
    "    except (ValueError) as e:\n",
    "        print(i,neg_geo['tile'][i],aerial_file,solar_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
